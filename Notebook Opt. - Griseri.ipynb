{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "15961ba2-53d9-4baa-9844-de40bc711587",
   "metadata": {},
   "source": [
    "Manuel D. Griseri, 20242324, UEVE, M1MINT, Année 2024-2025\n",
    "\n",
    "<h1 style=\"text-align: center;\">Projet Optimisation</h1>\n",
    "\n",
    "## 1. Méthode de Markowitz multi-scénario\n",
    "\n",
    "Nous considérons un problème de type Markowitz. Soient :\n",
    "\n",
    "- $x \\in \\mathbb{R}^n$ le vecteur de décision (poids du portefeuille).\n",
    "- $\\mu \\in \\mathbb{R}^n$ le vecteur des performances espérées.\n",
    "- $K \\in \\mathbb{R}^{n \\times n}$ la matrice de variance-covariance (symétrique définie positive).\n",
    "- $\\rho > 0$ le coefficient d’aversion au risque.\n",
    "- $X_0 > 0$ le capital initial que l’on peut fixer à 1 pour simplifier.\n",
    "\n",
    "Dans la version multi-scénario, on suppose que $\\mu$ et $K$ peuvent varier (dans notre cas seulement $\\mu$) selon différents scénarios $s$. On regroupe tous les scénarios possibles dans un ensemble admissible\n",
    "\n",
    "$$\n",
    "S_{\\mathrm{ad}} \\subset \\{(\\mu,K)\\}\n",
    "$$\n",
    "\n",
    "et on définit une fonction critère dépendant de $s=(\\mu,K)$ et de $x$ :\n",
    "\n",
    "$$\n",
    "J(s,x) = \\langle \\mu,\\; x\\rangle - \\frac{\\rho}{2}\\,X_{0} \\,\\langle Kx,\\; x\\rangle\n",
    "$$\n",
    "\n",
    "On se donne également un ensemble de portefeuilles admissibles $X_{\\mathrm{ad}} \\subset \\mathbb{R}^n$, par exemple le simplexe standard (on ne peut pas vendre à découvert et on doit utiliser tout notre capital, sans dépasser sa totalité) :\n",
    "\n",
    "$$\n",
    "X_{\\mathrm{ad}} = \\{\\,x \\in \\mathbb{R}^n : x_i \\ge 0,\\; \\sum_{i=1}^n x_i = 1\\}\n",
    "$$\n",
    "\n",
    "L’objectif est de déterminer la stratégie $x$ qui reste la meilleure dans le pire scénario $s$. Cela se formalise par\n",
    "\n",
    "$$\n",
    "\\min_{s \\in S_{\\mathrm{ad}}} \\; \\max_{x \\in X_{\\mathrm{ad}}} J(s, x)\n",
    "$$\n",
    "\n",
    "**1.1.**\n",
    "\n",
    "- L’ensemble $X_{\\mathrm{ad}}$, comme le simplexe standard ou tout polytope décrit par des conditions linéaires, est convexe et compact (fermé et borné). Un ensemble $C$ est dit convexe lorsque, pour tous $x$ et $y$ de $C$, le segment $[x, y]$ est tout entier contenu dans $C$, c'est-à-dire :\n",
    "\n",
    "$$\n",
    "\\forall x, y \\in C \\quad \\forall t \\in [0, 1] \\quad t x + (1 - t) y \\in C\n",
    "$$\n",
    "\n",
    "Montrons donc la convexité du simplexe. Prenons deux points $x, y \\in X_{\\mathrm{ad}}$. Par définition, cela signifie : $x_i \\ge 0$, $y_i \\ge 0$, $\\sum_{i=1}^n x_i = 1$ et $\\sum_{i=1}^n y_i = 1$. Considérons, pour un $t \\in [0,1]$, la combinaison\n",
    "\n",
    "$$\n",
    "z \\;=\\; t \\, x \\;+\\; (1 - t) \\, y\n",
    "$$\n",
    "\n",
    "Comme $x_i \\ge 0$ et $y_i \\ge 0$, et $t \\in [0,1]$, on obtient :\n",
    "\n",
    "$$\n",
    "z_i \\;=\\; t \\, x_i \\;+\\; (1 - t)\\,y_i \\ge 0\n",
    "$$\n",
    "\n",
    "Alors, $z \\in X_{\\mathrm{ad}}$ puisque\n",
    "\n",
    "$$\n",
    "\\sum_{i=1}^n z_i = \\sum_{i=1}^n \\bigl(t\\,x_i + (1 - t)\\,y_i\\bigr) = t \\sum_{i=1}^n x_i + (1 - t)\\sum_{i=1}^n y_i = t \\cdot 1 + (1 - t) \\cdot 1 = 1\n",
    "$$\n",
    "\n",
    "L’ensemble $S_{\\mathrm{ad}}$, où $\\mu$ est borné dans une boule ou un polytope et $K$ dans un domaine de matrices définies positives, est aussi convexe et compact sous des hypothèses de bornes appropriées. De plus, la fonction $J(s,x)$ est continue en $(s,x)$. Par le théorème de Weierstrass, on dispose ainsi de l’existence de solutions pour les problèmes min–max ou max–min.\n",
    "\n",
    "- L'inégalité suivante est triviale :\n",
    "\n",
    "$$\n",
    "\\min_{s \\in S_{\\mathrm{ad}}} \\max_{x \\in X_{\\mathrm{ad}}} J(s,x) \\leq \\max_{x \\in X_{\\mathrm{ad}}} \\min_{s \\in S_{\\mathrm{ad}}} J(s,x)\n",
    "$$\n",
    "\n",
    "Le théorème de Von Neumann affirme : soit $f : K_1 \\times K_2 \\to \\mathbb{R}$ une fonction continue où $K_1 \\subset \\mathbb{R}^n$ et $K_2 \\subset \\mathbb{R}^m$ sont des ensembles convexes compacts. Si $f$ est une fonction convexe-concave, c'est-à-dire que\n",
    "\n",
    "$$\n",
    "f(\\cdot, y) : K_1 \\to \\mathbb{R} \\text{ est convexe pour } y \\text{ fixé}\n",
    "$$\n",
    "\n",
    "$$\n",
    "f(x, \\cdot) : K_2 \\to \\mathbb{R} \\text{ est concave pour } x \\text{ fixé}\n",
    "$$\n",
    "\n",
    "alors\n",
    "\n",
    "$$\n",
    "\\min_{x \\in K_1} \\max_{y \\in K_2} f(x, y) = \\max_{y \\in K_2} \\min_{x \\in K_1} f(x, y)\n",
    "$$\n",
    "\n",
    "Puisque J est continue, concave en $x$ et affine en $\\mu$ (en particulier convexe), $X_{\\mathrm{ad}}$ et $S_{\\mathrm{ad}}$ sont convexes, alors en appliquant le théorème\n",
    "\n",
    "$$\n",
    "\\min_{s \\in S_{\\mathrm{ad}}} \\max_{x \\in X_{\\mathrm{ad}}} J(s,x) = \\max_{x \\in X_{\\mathrm{ad}}} \\min_{s \\in S_{\\mathrm{ad}}} J(s,x)\n",
    "$$\n",
    "\n",
    "- L’unicité n’est pas nécessairement garantie si la fonction n’est pas strictement convexe ou concave.\n",
    "\n",
    "**2.1.** Il existe alors un point-selle $(s^*, x^*)$ qui résout ce problème, puisque un point selle est définie comme : soient $X$ et $Y$ deux ensembles et $f : X \\times Y \\to \\mathbb{R}$ une fonction pouvant prendre les valeurs $\\pm\\infty$. On dit que $(\\bar{x}, \\bar{y}) \\in X \\times Y$ est un point-selle de $f$ sur $X \\times Y$ si\n",
    "\n",
    "$$\n",
    "\\forall (x, y) \\in X \\times Y : f(\\bar{x}, y) \\leq f(\\bar{x}, \\bar{y}) \\leq f(x, \\bar{y})\n",
    "$$\n",
    "\n",
    "Le passage par la recherche d’un point-selle offre un moyen de résolution : pour un scénario donné, on calcule la meilleure réponse en $x$, puis on cherche le scénario qui minimise la valeur obtenue. On peut itérer ce processus ou utiliser des méthodes primal-duales pour converger vers $(s^*, x^*)$. Ainsi, la compacité et la convexité des ensembles, jointes à la continuité et convexité-concavité de la fonction $J$, garantissent l’existence d’une solution et la possibilité de la résoudre par des approches en point-selle."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e7b3ea0-6727-4999-b102-6914bf73159e",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "## 2. Algorithme de Franck et Wolfe sous contraintes\n",
    "\n",
    "On cherche à résoudre, pour un $ \\mu $ donné, le problème\n",
    "\n",
    "$$\n",
    "\\max_{x \\in X_{\\mathrm{ad}}} \\; J(\\mu,x)\n",
    "$$\n",
    "\n",
    "La fonction $ J(\\mu,x) $ est de classe $ C^1 $ en $ x $, son gradient par rapport à $ x $ est \n",
    "\n",
    "$$\n",
    "\\nabla_x J(\\mu,x) = \\mu - \\rho\\,K\\,x\n",
    "$$\n",
    "\n",
    "Le schéma de Frank–Wolfe s’applique à la maximisation (ou minimisation) d’une fonction différentiable sur un convexe borné, et il converge dès que la fonction est concave (ou convexe si l’on minimise) et que l’ensemble des contraintes est compact. L’idée de l’algorithme est de définir pour la mise à jour un nouveau point dans l’ensemble des contraintes qui provient en fait d’un développement au premier ordre de la fonction autour du point courant. L’énorme avantage de ce type d’approche est qu’il n’y a pas d’étape de projection. Au voisinage de $ x_k $, on a\n",
    "\n",
    "$$\n",
    "J(x) = J(x_k) \\;+\\; \\langle \\nabla J(x_k), x - x_k\\rangle \\;+\\; o(x - x_k)\n",
    "$$\n",
    "\n",
    "Comme on maximise $ J $, cela revient localement à maximiser \n",
    "\n",
    "$$\n",
    "\\langle \\nabla J(x_k), x\\rangle\n",
    "$$\n",
    "\n",
    "sous la contrainte $ x \\in X_{\\mathrm{ad}} $. C’est un problème linéaire en $ x $ (puisque $ \\nabla J(x_k) $ est un vecteur fixé). On obtient un point $ \\tilde x_{k+1} $ solution de ce problème linéaire. Dans le cas d'un simplexe standard la solution est triviale, il faut mettre tout le poids sur la plus grande coordonnée du gradient. Dans le cas d'ensemble plus compliqués, on pourrait importer `linlog` de la bibliothèque `scipy.optimize`. Puis on effectue une recherche de pas $ \\tau_{k+1} \\in [0,1] $ maximisant \n",
    "\n",
    "$$\n",
    "J\\bigl((1-\\tau)x_k + \\tau\\,\\tilde x_{k+1}\\bigr)\n",
    "$$\n",
    "\n",
    "La mise à jour s’écrit\n",
    "\n",
    "$$\n",
    "x_{k+1} = (1-\\tau_{k+1})\\,x_k + \\tau_{k+1}\\,\\tilde{x}_{k+1}\n",
    "$$\n",
    "\n",
    "L’algorithme itère jusqu’à ce que $ \\|x_{k+1} - x_k\\| $ soit petit (critère d’arrêt). $ J $ est quadratique en $ x $ :\n",
    "\n",
    "$$\n",
    "J(x) = \\mu^\\top x \\;-\\; \\frac{\\rho}{2}\\,x^\\top K\\,x\n",
    "$$\n",
    "\n",
    "En remplaçant $ x $ par la combinaison barycentrique $ (1-\\tau)x_k + \\tau\\,\\tilde x_{k+1} $, on obtient une fonction en $ \\tau $ :\n",
    "\n",
    "$$\n",
    "f(\\tau) = J\\bigl((1-\\tau)x_k + \\tau\\,\\tilde x_{k+1}\\bigr), \\quad \\tau \\in [0,1]\n",
    "$$\n",
    "\n",
    "C’est une fonction unidimensionnelle et (pour $ \\rho > 0 $ et $ K $ définie positive) cette fonction est concave en $ \\tau $, d’où l’existence d’un maximum dans $ [0,1] $. On peut en déduire une formule fermée pour $ \\tau_{k+1} $ en résolvant $ \\frac{d}{d\\tau}f(\\tau)=0 $.\n",
    "\n",
    "$$\n",
    "x_{k+1}(\\tau) = (1 - \\tau)\\,x_k \\;+\\; \\tau\\,\\tilde{x}_{k+1}, \\quad d = \\tilde{x}_{k+1} - x_k\n",
    "$$\n",
    "\n",
    "$$\n",
    "f(\\tau) = \\langle \\mu,\\; x_{k+1}(\\tau)\\rangle \\;-\\; \\frac{\\rho}{2}\\, \\bigl(x_{k+1}(\\tau)\\bigr)^\\top\\,K\\, \\bigl(x_{k+1}(\\tau)\\bigr)\n",
    "$$\n",
    "\n",
    "$$\n",
    "f(\\tau) = \\mu^\\top\\bigl(x_k + \\tau\\,d\\bigr) \\;-\\; \\frac{\\rho}{2}\\,\\bigl(x_k + \\tau\\,d\\bigr)^\\top K\\,\\bigl(x_k + \\tau\\,d\\bigr)\n",
    "$$\n",
    "\n",
    "$$\n",
    "= \\mu^\\top x_k - \\frac{\\rho}{2}\\,x_k^\\top K\\,x_k \\;+\\; \\tau\\,\\Bigl(\\mu^\\top d \\;-\\; \\rho\\, x_k^\\top K\\,d\\Bigr) \\;-\\; \\frac{\\rho}{2}\\,\\tau^2\\,\\bigl(d^\\top K\\,d\\bigr)\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\frac{d}{d\\tau}f(\\tau) = \\mu^\\top d \\;-\\; \\rho\\,x_k^\\top K\\,d \\;-\\; \\rho\\,\\tau\\,\\bigl(d^\\top K\\,d\\bigr) = 0\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\rho\\,\\tau\\,\\bigl(d^\\top K\\,d\\bigr) = \\mu^\\top d \\;-\\; \\rho\\,x_k^\\top K\\,d \\quad\\Longrightarrow\\quad \\tau = \\frac{\\mu^\\top d \\;-\\;\\rho\\,x_k^\\top K\\,d}{\\rho\\,\\bigl(d^\\top K\\,d\\bigr)}\n",
    "$$\n",
    "\n",
    "Puisque $\\tau \\in [0,1]$ :\n",
    "\n",
    "$$\n",
    "\\tau_{k+1} = \\max\\Bigl\\{0,\\, \\min\\Bigl\\{1,\\, \\frac{\\mu^\\top d \\;-\\;\\rho\\,\\bigl(x_k^\\top K\\,d\\bigr)} {\\rho\\,\\bigl(d^\\top K\\,d\\bigr)} \\Bigr\\}\\Bigr\\}\n",
    "$$\n",
    "\n",
    "Ci-dessous, un exemple d’implémentation en Python. L'algorithme suggère d'investir environ 14% de notre capital dans le premier actif et 43% dans chacun des deuxième et troisième actifs. Enfin, il est intéressant de comparer le résultat avec la solution de l'optimisation sans contraintes (en supposant que $K$ est inversible, on résout l'équation où le gradient s'annule) :\n",
    "\n",
    "$$\n",
    "x^* = \\frac{1}{\\rho} K^{-1} \\mu\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "db706787-9964-415b-967e-8e1a3c39db21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solution x_free = [0.2972973  0.51351351 0.62162162]\n",
      "Solution x_opt = [0.14285822 0.42857116 0.42857062]\n",
      "Vérification somme(x_opt) = 1.0\n",
      "Critère J(x_opt) = 0.1035714285712105\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def J(mu, K, x, rho=1.0):\n",
    "    return mu @ x - 0.5 * rho * (x @ K @ x)\n",
    "\n",
    "def gradJ(mu, K, x, rho=1.0):\n",
    "    return mu - rho * (K @ x)\n",
    "\n",
    "def simplexe_max(grad, x_dim):\n",
    "    e = np.zeros(x_dim)\n",
    "    i_star = np.argmax(grad)\n",
    "    e[i_star] = 1.0\n",
    "    return e\n",
    "\n",
    "def tau(mu, K, xk, sk, rho=1.0): \n",
    "    d = sk - xk\n",
    "    t_star = (mu @ d - rho * (xk @ K @ d)) / (rho * (d @ K @ d))\n",
    "    t_star = max(min(t_star, 1.0), 0.0)   # On projette dans [0,1]\n",
    "    return t_star\n",
    "\n",
    "def frank_wolfe(mu, K, x0, rho=1.0, max_iter=100, eps=1e-6):\n",
    "    xk = x0\n",
    "    for k in range(max_iter):\n",
    "        grad = gradJ(mu, K, xk, rho)\n",
    "        # On détermine sk via l'algorithme du simplexe\n",
    "        sk = simplexe_max(grad, len(xk))  \n",
    "        tk = tau(mu, K, xk, sk, rho)       # On trouve tk\n",
    "        x_next = (1 - tk) * xk + tk * sk   # Mise à jour\n",
    "        if k == 0:\n",
    "            x1 = x_next\n",
    "        # Critère d'arrêt\n",
    "        if np.linalg.norm(x_next - xk) < (eps * np.linalg.norm(x1 - x0)):  \n",
    "            xk = x_next\n",
    "            break \n",
    "        xk = x_next\n",
    "    return xk\n",
    "\n",
    "# Exemple d'utilisation\n",
    "if __name__ == \"__main__\":\n",
    "    n = 3\n",
    "    mu = np.array([0.1, 0.2, 0.15])     # Espérance de rendement\n",
    "    K = np.array([[0.05, 0.01, 0.0],    # Matrice de covariance\n",
    "                  [0.01, 0.06, 0.01],\n",
    "                  [0.0,  0.01, 0.04]])\n",
    "    rho = 5.0\n",
    "    x0 = np.array([1.0, 0.0, 0.0])          # Point initial\n",
    "    x_opt = frank_wolfe(mu, K, x0, rho)     # Appel de l'algo\n",
    "    x_free = np.linalg.inv(K) @ mu / rho    # Optimisation sans contraintes\n",
    "    print(\"Solution x_free =\", x_free)\n",
    "    print(\"Solution x_opt =\", x_opt)\n",
    "    print(\"Vérification somme(x_opt) =\", x_opt.sum())\n",
    "    print(\"Critère J(x_opt) =\", J(mu, K, x_opt, rho))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7713936-8142-485c-9461-05f77500380e",
   "metadata": {},
   "source": [
    "### Convergence de l'algorithme\n",
    "\n",
    "On va maintenant montrer, dans un cas plus général, la convergence de l'algorithme. On considère un problème de minimisation qui, dans le cadre de l'optimisation de portefeuille, peut survenir lorsque, par exemple, on cherche à minimiser le risque. En appelant $C \\subset \\mathbb{R}^n$ un convexe borné vérifiant un critère de qualification. On construit alors $X_{k+1}$ suivant l’itération :\n",
    "\n",
    "$$\n",
    "X_{k+1} = (1 - \\gamma_{k+1}) \\, X_k \\;+\\; \\gamma_{k+1} \\, \\Theta_{k+1}, \\quad \\Theta_{k+1} \\in \\arg\\min_{\\Theta \\in C} \\langle \\nabla J(X_k), \\Theta \\rangle, \\quad \\gamma_{k+1} \\in [0,1]\n",
    "$$\n",
    "\n",
    "On précise ici que $\\arg\\min_{\\Theta \\in C} \\nabla J(X_k) \\cdot \\Theta$ est un ensemble car on n’a pas a priori unicité au problème linéaire ci-dessus. Par construction, comme $X_0 \\in C$ et $\\Theta_{1} \\in C$, par convexité du domaine de contrainte $C$ on a que pour tout $k$, $X_k \\in C$. Maintenant, on pose\n",
    "\n",
    "$$\n",
    "M := \\sup_{X,\\Theta \\in C,\\; Y=(1-\\gamma)X + \\gamma\\Theta,\\; \\gamma \\in [0,1]} \\; 2 \\gamma^{-2} \\bigl[ J(Y) - J(X) - \\nabla J(X)\\cdot(Y - X) \\bigr]\n",
    "$$\n",
    "\n",
    "On écrit par la formule de Taylor :\n",
    "\n",
    "$$\n",
    "J(Y) - J(X) - \\nabla J(X)\\cdot (Y - X) \n",
    "$$\n",
    "\n",
    "$$\n",
    "= \\int_0^1 d\\lambda\\,(1-\\lambda)\\, \\langle H_J\\bigl(X + \\lambda(Y - X)\\bigr) \\,(Y - X),\\,Y - X \\rangle\n",
    "$$\n",
    "\n",
    "De la définition de $M$ et $Y$, il vient donc :\n",
    "\n",
    "$$\n",
    "\\bigl|J(Y) - J(X) - \\nabla J(X)\\cdot (Y - X)\\bigr| \\;\\le\\; \\int_0^1 d\\lambda(1-\\lambda) \\sup_{Z \\in C} \\|H_J(Z)\\|\\;\\| \\Theta - X\\|^2 \n",
    "$$\n",
    "\n",
    "$$\n",
    "\\;\\le\\; \\gamma^2 \\sup_{Z \\in C}\\|H_J(Z)\\|\\; \\mathrm{diam}(C)^2 \\,/\\,2\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\Longrightarrow M \\;\\le\\; \\sup_{Z\\in C} \\|H_J(Z)\\|\\;\\mathrm{diam}(C)^2\n",
    "$$\n",
    "\n",
    "où \n",
    "\n",
    "$$\n",
    "\\text{diam}(C) = \\sup \\{ \\| x - y\\| \\mid x, y \\in C \\}\n",
    "$$\n",
    "\n",
    "On écrit de nouveau la formule de Taylor :\n",
    "\n",
    "$$\n",
    "J(X_{k+1}) = J(X_k) + \\nabla J(X_k)\\cdot (X_{k+1} - X_k) +\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\int_0^1 d\\lambda\\,(1-\\lambda)\\,\\langle H_J\\bigl(X_k + \\lambda(X_{k+1} - X_k)\\bigr)\\,(X_{k+1}-X_k),\\,X_{k+1}-X_k \\rangle\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\le J(X_k) - \\gamma_{k+1}\\,\\nabla J(X_k)\\cdot (\\Theta_{k+1} - X_k) + \\frac{\\gamma_{k+1}^2\\,M}{2}\n",
    "$$\n",
    "\n",
    "On rappelle maintenant que $\\nabla J(X_k)\\cdot \\Theta_{k+1} = \\min_{\\Theta \\in C} \\nabla J(X_k)\\cdot \\Theta$. En définissant $G(X) = \\max_{\\Theta\\in C}\\nabla J(X)\\cdot(X - \\Theta)$, on déduit :\n",
    "\n",
    "$$\n",
    "J(X_{k+1}) \\;\\le\\; J(X_k) \\;-\\; \\gamma_{k+1}\\,G(X_k) \\;+\\; \\frac{\\gamma_{k+1}^2\\,M}{2}\n",
    "$$\n",
    "\n",
    "Posons maintenant\n",
    "\n",
    "$$\n",
    "\\Delta_{k+1} := J(X_{k+1}) - J(X^*)\n",
    "$$\n",
    "\n",
    "$$\n",
    "0 \\;\\le\\; \\Delta_k = J(X_k) - J(X^*) = \\nabla J(X_k)\\cdot (X_k - X^*) + \\ldots  \n",
    "$$\n",
    "\n",
    "$$\n",
    "\\;\\le\\; \\nabla J(X_k)\\cdot (X_k - X^*) \\leq \\max_{\\Theta \\in C} \\nabla J(X_k)\\cdot (X_k - \\Theta) = G(X_k)\n",
    "$$\n",
    "\n",
    "On obtient alors,\n",
    "\n",
    "$$\n",
    "J(X_{k+1}) - J(X^*) \\;\\le\\; J(X_k) - J(X^*) - \\gamma_{k+1}\\,G(X_k) + \\frac{\\gamma_{k+1}^2 M}{2} \n",
    "$$\n",
    "\n",
    "$$\n",
    "\\;\\le\\; \\Delta_k\\,(1 - \\gamma_{k+1}) + \\frac{\\gamma_{k+1}^2 M}{2}\n",
    "$$\n",
    "\n",
    "Introduisons pour $k \\in \\mathbb{N}$ la proposition de récurrence\n",
    "\n",
    "$$\n",
    "(P_k),\\quad 0 \\;\\le\\; J(X_k) - J(X^*) \\;\\le\\; \\frac{2\\,M}{k + 2}\n",
    "$$\n",
    "\n",
    "Il est clair que \n",
    "\n",
    "$$\n",
    "J(X_0) - J(X^*) = \\int_0^1 d\\lambda(1-\\lambda)\\,\\langle H_J\\bigl(X^* + \\lambda(X_0 - X^*)\\bigr)\\,(X_0 - X^*),\\,X_0 - X^*\\bigr \\rangle \\le M\n",
    "$$\n",
    "\n",
    "et donc $(P_0)$ est bien vérifiée. Si l’on suppose maintenant $(P_k)$ vraie à un rang $k$ donné, pour $\\gamma_{k+1} = \\frac{2}{k+2}$ :\n",
    "\n",
    "$$\n",
    "\\Delta_{k+1} := J(X_{k+1}) - J(X^*) \\;\\le\\; \\Delta_k\\,(1 - \\gamma_{k+1}) + \\gamma_{k+1}^2\\,\\frac{M}{2} \n",
    "$$\n",
    "\n",
    "$$\n",
    "\\;\\le\\; \\frac{2\\,M}{k+2}\\Bigl(1 - \\frac{2}{k+2}\\Bigr) + \\Bigl(\\frac{2}{k+2}\\Bigr)^2\\,\\frac{M}{2}\n",
    "$$ \n",
    "\n",
    "$$\n",
    "\\frac{2\\,M}{k+2}\\Bigl(1 - \\frac{2}{k+2}\\Bigr) = \\frac{2\\,M\\,k}{(k+2)^2}, \\quad \\Bigl(\\frac{2}{k+2}\\Bigr)^2 \\frac{M}{2} = \\frac{2\\,M}{(k+2)^2}\n",
    "$$\n",
    "\n",
    "Donc au total,\n",
    "\n",
    "$$\n",
    "\\Delta_{k+1} \\;\\le\\; \\frac{2\\,M\\,k}{(k+2)^2} + \\frac{2\\,M}{(k+2)^2} = \\frac{2\\,M\\,(k+1)}{(k+2)^2} \\;\\le\\; \\frac{2\\,M}{k+3}\n",
    "$$\n",
    "\n",
    "ce qui établit $(P_{k+1})$ et achève la récurrence. De plus, la convergence est sub-linéaire, de l'ordre $O\\left(\\frac{1}{k}\\right)$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e18b23c-6a0f-4d60-83ff-662464f7e81f",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "## 3. Algorithme complet\n",
    "\n",
    "**3.1.** \n",
    "\n",
    "- $\\rho K$ est symétrique définie positive. Il existe alors une décomposition de Cholesky de $\\rho K$ :\n",
    "\n",
    "$$\n",
    "\\rho K \\;=\\; L\\,L^\\top\n",
    "$$\n",
    "\n",
    "où $L$ est une matrice triangulaire inférieure (coefficients diagonaux strictement positifs, donc elle est inversible). Pour la preuve de la factorisation de Cholesky, il faut utiliser le fait qu'une matrice symétrique définie positive représente un certain produit scalaire dans la base canonique. On prend alors une autre base, orthonormée pour ce produit scalaire. On note $P$ la matrice de passage entre les deux bases. La formule de changement de base pour une application bilinéaire donne $\\rho K = P^T I_n P = P^T P$. On va chercher à bien choisir la nouvelle base de sorte que $P$ soit triangulaire supérieure à coefficients diagonaux positifs. L'algorithme de Gram-Schmidt garantit l'existence et l'unicité d'une telle base, d'où l'existence et l'unicité de $P$. Enfin, on pose $L = P^T$ dont on déduit la forme voulue.\n",
    "\n",
    "- Voici comment on passe de\n",
    "\n",
    "$$\n",
    "\\max_{x \\in X_{\\mathrm{ad}}} \\Bigl[\\mu^\\top x - \\frac{\\rho}{2}\\,x^\\top K\\,x\\Bigr]\n",
    "$$\n",
    "\n",
    "à\n",
    "\n",
    "$$\n",
    "\\frac12 \\Bigl[ \\langle K\\mu,\\;\\mu\\rangle \\;-\\; d^2\\bigl(L^{-1}\\mu,\\;L^\\top X_{\\mathrm{ad}}\\bigr) \\Bigr]\n",
    "$$\n",
    "\n",
    "en utilisant la décomposition $\\rho K = L\\,L^\\top$ et un changement de variable adapté. \n",
    "\n",
    "$$\n",
    "\\mu^\\top x \\;-\\; \\frac{\\rho}{2}\\,x^\\top K\\,x \\;=\\; \\mu^\\top x \\;-\\; \\frac12\\,x^\\top (\\rho K)\\,x \\;=\\; \\mu^\\top x \\;-\\; \\frac12 \\,\\bigl\\|\\,L^\\top x\\,\\bigr\\|^2\n",
    "$$\n",
    "\n",
    "$$\n",
    "z \\;=\\; L^\\top x, \\quad y \\;=\\; L^{-1}\\,\\mu\n",
    "$$\n",
    "\n",
    "Alors $\\mu^\\top x = (L\\,y)^\\top x = y^\\top (L^\\top x) = y^\\top z$ et donc\n",
    "\n",
    "$$\n",
    "y^\\top z \\;-\\; \\frac12\\,\\|z\\|^2, \\quad \\text{où }z \\in L^\\top X_{\\mathrm{ad}}\n",
    "$$\n",
    "\n",
    "On note que\n",
    "\n",
    "$$\n",
    "y^\\top z - \\frac12\\,\\|z\\|^2 \\;=\\; -\\,\\frac12\\,\\|\\,z - y\\|^2 \\;+\\; \\frac12\\,\\|y\\|^2\n",
    "$$\n",
    "\n",
    "Par conséquent,\n",
    "\n",
    "$$\n",
    "\\max_{z \\,\\in\\,L^\\top X_{\\mathrm{ad}}} \\Bigl( y^\\top z - \\frac12\\|z\\|^2 \\Bigr) = \\max_{z \\,\\in\\,L^\\top X_{\\mathrm{ad}}} \\Bigl[ -\\,\\frac12\\,\\|z - y\\|^2 + \\frac12\\,\\|y\\|^2 \\Bigr] = \\frac12\\,\\Bigl[ \\|y\\|^2 -\\! \\min_{\\,z\\in\\,L^\\top X_{\\mathrm{ad}}}\\!\\|z - y\\|^2 \\Bigr]\n",
    "$$\n",
    "\n",
    "On aboutit ainsi à\n",
    "\n",
    "$$\n",
    "\\max_{x \\in X_{\\mathrm{ad}}} \\Bigl[ \\mu^\\top x - \\frac{\\rho}{2}\\,x^\\top K\\,x \\Bigr] = \\frac12 \\Bigl[ \\langle K\\mu,\\;\\mu\\rangle \\;-\\; d^2\\bigl(L^{-1}\\mu,\\;L^\\top X_{\\mathrm{ad}}\\bigr) \\Bigr]\n",
    "$$\n",
    "\n",
    "où\n",
    "\n",
    "$$\n",
    "d^2(y,\\,C) \\;=\\; \\min_{z\\in C} \\|\\,z - y\\|^2 \\;=\\; \\|\\,y - \\Pi_C(y)\\|^2\n",
    "$$\n",
    "\n",
    "**3.1.a.** Pour un convexe fermé $C\\subset \\mathbb{R}^n$, la fonction\n",
    "\n",
    "$$\n",
    "\\varphi_C(y) \\;=\\; \\|\\,y - \\Pi_C(y)\\,\\|^2\n",
    "$$\n",
    "\n",
    "est bien définie car $\\Pi_C(y)$ existe et est unique (toute partie convexe fermée non vide admet une projection orthogonale) et la norme est bien définie.\n",
    "\n",
    "**3.1.b.** La différentiabilité de $\\varphi_C(y)$ repose sur celle de $\\Pi_C(y)$ lorsque $C$ est un convexe fermé. Pour calculer le gradiant, on développe la norme au carré :\n",
    "\n",
    "$$\n",
    "\\varphi_C(y) = \\sum_{i=1}^n (y_i - \\Pi_C(y)_i)^2\n",
    "$$\n",
    "\n",
    "Alors,\n",
    "\n",
    "$$\n",
    "\\nabla \\varphi_C(y) = 2(y - \\Pi_C(y))\n",
    "$$\n",
    "\n",
    "**3.1.c.** \n",
    "\n",
    "$$\n",
    "H(\\mu) = \\frac{1}{2} \\Big[ \\langle K\\mu, \\mu \\rangle - \\varphi_{L^\\top X_{\\mathrm{ad}}}(L^{-1} \\mu) \\Big]\n",
    "$$\n",
    "\n",
    "La première partie $\\frac{1}{2} \\langle K\\mu, \\mu \\rangle$ est quadratique en $\\mu$, donc elle est de classe $C^1$. La seconde partie est composée de : $L^{-1}$, une application linéaire qui est différentiable, $\\varphi_{L^\\top X_{\\mathrm{ad}}}$, qui est différentiable comme montré au point b. Ainsi, $H(\\mu)$ est de classe $C^1$ sur $\\mathbb{R}^n$.\n",
    "\n",
    "$$\n",
    "\\nabla H(\\mu) = K\\mu - (L^{-1})^\\top \\Big( L^{-1} \\mu - \\Pi_{L^\\top X_{\\mathrm{ad}}}(L^{-1} \\mu) \\Big)\n",
    "$$\n",
    "\n",
    "$$\n",
    "x(\\mu) = \\arg\\max_{x \\in X_{\\text{ad}}} \\Big[ \\langle \\mu, x \\rangle - \\frac{\\rho}{2} \\langle Kx, x \\rangle \\Big]\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\quad\\Longrightarrow\\quad \\nabla H(\\mu) = x(\\mu)\n",
    "$$\n",
    "\n",
    "En d'autres termes, le gradient capture la relation entre le problème dual (en $\\mu$) et le problème primal (en $x$).\n",
    "\n",
    "**3.2.** La fonction $H(\\mu)$ est un maximum de fonctions, chacune étant affine en $\\mu$, alors le max de fonctions convexes reste convexe, donc $H$ est convexe. Pour démontrer que si une fonction $f(x, y)$ est convexe en $x$ et affine en $y$, alors $\\max_x f(x, y)$ est convexe, procédons comme suit. Convexité en $x$ : pour tout $y$, et pour tout $x_1, x_2 \\in \\mathbb{R}^n$ et $\\lambda \\in [0, 1]$,\n",
    "\n",
    "$$\n",
    "f(\\lambda x_1 + (1 - \\lambda)x_2, y) \\leq \\lambda f(x_1, y) + (1 - \\lambda)f(x_2, y)\n",
    "$$\n",
    "\n",
    "Affinité en $y$ : $f$ peut s'écrire sous la forme\n",
    "\n",
    "$$\n",
    "f(x, y) = p(x) + \\langle h(x), y \\rangle\n",
    "$$\n",
    "\n",
    "où $p(x)$ est une fonction en $x$ et $h(x)$ est une fonction vectorielle en $x$. On définie $g(y)$ comme\n",
    "\n",
    "$$\n",
    "g(y) := \\max_x f(x, y)\n",
    "$$\n",
    "\n",
    "Cela signifie que $g(y)$ est l'enveloppe supérieure des valeurs de $f(x, y)$ sur $x$, pour un $y$ donné. Pour prouver que $g(y)$ est convexe, il faut montrer que pour tout $y_1, y_2$ et $\\lambda \\in [0, 1]$,\n",
    "\n",
    "$$\n",
    "g(\\lambda y_1 + (1 - \\lambda)y_2) \\leq \\lambda g(y_1) + (1 - \\lambda)g(y_2)\n",
    "$$\n",
    "\n",
    "Par définition de $g(y)$,\n",
    "\n",
    "$$\n",
    "g(y_1) = \\max_x f(x, y_1), \\quad g(y_2) = \\max_x f(x, y_2)\n",
    "$$\n",
    "\n",
    "De plus,\n",
    "\n",
    "$$\n",
    "g(\\lambda y_1 + (1 - \\lambda)y_2) = \\max_x f(x, \\lambda y_1 + (1 - \\lambda)y_2)\n",
    "$$\n",
    "\n",
    "Puisque $f(x, y)$ est affine en $y$ et on considère une combinaison barycentrique, on a\n",
    "\n",
    "$$\n",
    "f(x, \\lambda y_1 + (1 - \\lambda)y_2) = \\lambda f(x, y_1) + (1 - \\lambda)f(x, y_2)\n",
    "$$\n",
    "\n",
    "Prenons le maximum de chaque côté de cette équation par rapport à $x$. Le maximum d'une somme pondérée est inférieur ou égal à la somme pondérée des maxima :\n",
    "\n",
    "$$\n",
    "\\max_x f(x, \\lambda y_1 + (1 - \\lambda)y_2) \\leq \\lambda \\max_x f(x, y_1) + (1 - \\lambda) \\max_x f(x, y_2)\n",
    "$$\n",
    "\n",
    "En réécrivant, on a\n",
    "\n",
    "$$\n",
    "g(\\lambda y_1 + (1 - \\lambda)y_2) \\leq \\lambda g(y_1) + (1 - \\lambda)g(y_2)\n",
    "$$\n",
    "\n",
    "Ainsi, $g(y)$ est convexe. $H(\\mu)$ est strictement convexe si, pour chaque $\\mu$, le $x(\\mu)$ est unique et dépend de $\\mu$ de manière stricte (ce qui peut arriver si $K$ est strictement définie positive et si les contraintes ne provoquent pas de « plateau »). Sinon, il peut exister plusieurs $x(\\mu)$ donnant la même valeur et donc la convexité n’est pas stricte.\n",
    "\n",
    "**3.3.** On cherche à minimiser $H(\\mu)$ sur un domaine $U_{\\mathrm{ad}}\\subset \\mathbb{R}^n$. Ici, $U_{\\mathrm{ad}}$ a été considéré comme un simplexe standard; cependant, cela n’a pas une interprétation financière adéquate, car limiter les rendements à être uniquement positifs et à sommer à 1 n’est pas réaliste. Itération : à $\\mu_k$ connu, on calcule $\\nabla H(\\mu_k) = x(\\mu_k)$ en utilisant l'algorithme de la partie 2. Puis on cherche à minimiser (en $\\mu$) dans cette direction. Cela fournit $\\tilde \\mu_{k+1}$. En effet, c’est un schéma Frank–Wolfe sur la fonction duale $H$ : on utilise $\\nabla H(\\mu_k)$ pour l’approximation linéaire, puis on effectue la recherche de pas optimal $\\rho_{k+1}$.  On pose\n",
    "\n",
    "$$\n",
    "\\mu_{k+1} \\;=\\; (1-\\rho_{k+1})\\,\\mu_k \\;+\\; \\rho_{k+1}\\,\\tilde{\\mu}_{k+1}, \\quad \\rho_{k+1} := \\arg\\max_{\\rho\\in[0,1]} H\\bigl((1-\\rho)\\,\\mu_k + \\rho\\,\\tilde{\\mu}_{k+1}\\bigr)\n",
    "$$\n",
    "\n",
    "On s'arrête quand $\\|\\mu_{k+1} - \\mu_k\\| < \\varepsilon\\,\\|\\mu_1 - \\mu_0\\|$. Vu la difficulté de trouvé une expression analitique pour $\\rho_{k+1}$ on utilise un algorithme d'échantillonage de l'intervalle $[0,1]$. Ci-dessous un exemple d’implémentation en Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b04452d9-1c4c-4428-a160-e9e72448f1c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solution mu_star = [0.31248 0.1922  0.49532]\n",
      "H(mu_star) = 0.395647184\n",
      "Solution x_opt = [0.03813333 0.         0.96186667]\n"
     ]
    }
   ],
   "source": [
    "def H(mu, K, x0, rho=1.0):\n",
    "    x_star = frank_wolfe(mu, K, x0, rho)\n",
    "    val = mu @ x_star - 0.5 * rho * (x_star @ K @ x_star)\n",
    "    return val\n",
    "\n",
    "def gradH(mu, K, x0, rho=1.0):\n",
    "    return frank_wolfe(mu, K, x0, rho)\n",
    "\n",
    "def simplexe_min(grad, x_dim):\n",
    "    e = np.zeros(x_dim)\n",
    "    i_star = np.argmin(grad)\n",
    "    e[i_star] = 1.0\n",
    "    return e\n",
    "\n",
    "def alpha_sampling(mu_k, gk, K, x0, rho=1.0):\n",
    "    best_val = -np.inf\n",
    "    best_alpha = 0.0\n",
    "    nb_samples = 51   # On échantillonne sur 50 points dans [0, 1]\n",
    "    for i in range(nb_samples):\n",
    "        alpha = i / (nb_samples - 1)\n",
    "        mu_test = (1 - alpha) * mu_k + alpha * gk\n",
    "        val = H(mu_test, K, x0, rho)\n",
    "        if val > best_val:\n",
    "            best_val = val\n",
    "            best_alpha = alpha      \n",
    "    return best_alpha\n",
    "    \n",
    "def frank_wolfe_H(mu0, K, x0, rho=1.0, max_iter=100, eps=1e-6):\n",
    "    mu_k = mu0\n",
    "    for k in range(max_iter):\n",
    "        grad = gradH(mu_k, K, x0, rho)\n",
    "        gk = simplexe_min(grad, len(mu_k))\n",
    "        alpha = alpha_sampling(mu_k, gk, K, x0, rho)\n",
    "        mu_next = (1 - alpha) * mu_k + alpha * gk\n",
    "        if k == 0:\n",
    "            mu1 = mu_next\n",
    "        if np.linalg.norm(mu_next - mu_k) < (eps * np.linalg.norm(mu1 - mu0)):\n",
    "            mu_k = mu_next\n",
    "            break\n",
    "        mu_k = mu_next\n",
    "    return mu_k\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    n = 3\n",
    "    mu0 = np.array([0.2, 0.5, 0.3])   \n",
    "    K = np.array([[0.05, 0.01, 0.0],  \n",
    "                  [0.01, 0.06, 0.01],\n",
    "                  [0.0,  0.01, 0.04]])\n",
    "    rho = 5.0\n",
    "    x0 = np.array([1.0, 0.0, 0.0])\n",
    "    mu_star = frank_wolfe_H(mu0, K, x0, rho)\n",
    "    x_opt = frank_wolfe(mu_star, K, x0, rho)\n",
    "    print(\"Solution mu_star =\", mu_star)\n",
    "    print(\"H(mu_star) =\", H(mu_star, K, x0, rho))\n",
    "    print(\"Solution x_opt =\", x_opt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d04e5399-f6d5-41b6-806c-ce774c92ecea",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "## Bibliographie\n",
    "- Jaggi, M. (2013). Revisiting Frank-Wolfe: projection-free sparse convex optimization (Proceedings of the 30th International Conference on Machine Learning). École Polytechnique.\n",
    "- Lemarié-Rieusset, P. G. (2020). Algorithmes d'optimisation (polycopié). Université d'Évry.\n",
    "- Menozzi, S. Optimisation. 2024. Notes de cours. Université d'Évry."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
